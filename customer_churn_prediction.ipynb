{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Essential Imports (always at the top) ---\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "iP1vfAHmkqSE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customer Churn Prediction and Data Quality Analysis\n",
        "Problem Statement\n",
        "\n",
        "\n",
        "This project aims to demonstrate fundamental data science and machine learning skills by addressing a common business problem: customer churn. Customer churn, or customer attrition, refers to the rate at which customers stop doing business with an entity. Predicting churn allows businesses to proactively identify at-risk customers and implement retention strategies, which is often more cost-effective than acquiring new customers.\n",
        "\n",
        "Specifically, this project will:\n",
        "\n",
        "Perform essential data cleaning and preparation on a raw customer dataset.\n",
        "Build and train a basic machine learning model (Logistic Regression) to predict whether a customer is likely to churn.\n",
        "Evaluate the model's performance.\n",
        "This serves as a foundational portfolio piece showcasing skills in data handling, basic machine learning, and results interpretation."
      ],
      "metadata": {
        "id": "-F3_prlNkq0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading and Initial Inspection ---\n",
        "\n",
        "# Mock CSV data representing raw customer information\n",
        "csv_data = \"\"\"customer_id,age,gender,annual_income,has_loyalty_card,last_purchase_amount\n",
        "101,34,Female,55000,True,120.50\n",
        "102,45,Male,70000,False,23.10\n",
        "103,28,Female,48000,True,300.00\n",
        "104,52,Male,85000,True,75.25\n",
        "105,,Female,60000,False,\n",
        "106,30,Male,null,True,50.00\n",
        "107,39,Female,62000,False,180.75\n",
        "108,60,Male,90000,True,15.99\n",
        "\"\"\"\n",
        "\n",
        "# Load the data into a Pandas DataFrame\n",
        "df = pd.read_csv(io.StringIO(csv_data))\n",
        "\n",
        "# Convert 'null' string in annual_income to NaN (NumPy's representation for missing values)\n",
        "# and ensure the column is numeric. This is important for calculations like the mean.\n",
        "df['annual_income'] = df['annual_income'].replace('null', np.nan)\n",
        "df['annual_income'] = pd.to_numeric(df['annual_income'])\n",
        "\n",
        "print(\"--- Original DataFrame Head (First 5 Rows) ---\")\n",
        "print(df.head())\n",
        "print(\"\\n--- Original Missing Values Count per Column ---\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\n--- Original DataFrame Info (Data Types and Non-Nulls) ---\")\n",
        "df.info() # Displays data types and non-null counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBTBc7_Ek64j",
        "outputId": "e38f1350-88fb-4863-db25-91f0a3d58156"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Original DataFrame Head (First 5 Rows) ---\n",
            "   customer_id   age  gender  annual_income  has_loyalty_card  \\\n",
            "0          101  34.0  Female        55000.0              True   \n",
            "1          102  45.0    Male        70000.0             False   \n",
            "2          103  28.0  Female        48000.0              True   \n",
            "3          104  52.0    Male        85000.0              True   \n",
            "4          105   NaN  Female        60000.0             False   \n",
            "\n",
            "   last_purchase_amount  \n",
            "0                120.50  \n",
            "1                 23.10  \n",
            "2                300.00  \n",
            "3                 75.25  \n",
            "4                   NaN  \n",
            "\n",
            "--- Original Missing Values Count per Column ---\n",
            "customer_id             0\n",
            "age                     1\n",
            "gender                  0\n",
            "annual_income           1\n",
            "has_loyalty_card        0\n",
            "last_purchase_amount    1\n",
            "dtype: int64\n",
            "\n",
            "--- Original DataFrame Info (Data Types and Non-Nulls) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8 entries, 0 to 7\n",
            "Data columns (total 6 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   customer_id           8 non-null      int64  \n",
            " 1   age                   7 non-null      float64\n",
            " 2   gender                8 non-null      object \n",
            " 3   annual_income         7 non-null      float64\n",
            " 4   has_loyalty_card      8 non-null      bool   \n",
            " 5   last_purchase_amount  7 non-null      float64\n",
            "dtypes: bool(1), float64(3), int64(1), object(1)\n",
            "memory usage: 460.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Description\n",
        "\n",
        "The dataset used in this project is a mock customer dataset containing 8 entries (rows) and 6 features (columns). Each row represents a unique customer with attributes such as:\n",
        "\n",
        "customer_id: Unique identifier for each customer.\n",
        "age: Age of the customer.\n",
        "gender: Gender of the customer (categorical: Female/Male).\n",
        "annual_income: Customer's annual income.\n",
        "has_loyalty_card: Boolean indicating if the customer has a loyalty card.\n",
        "last_purchase_amount: Amount of the customer's last purchase.\n",
        "Initial inspection revealed missing values in the age, annual_income (represented as 'null' string initially), and last_purchase_amount columns, which require cleaning before model building."
      ],
      "metadata": {
        "id": "IKrV-dFolOC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Data Cleaning Steps ---\n",
        "\n",
        "# Explanation of Data Cleaning:\n",
        "# Real-world data is often messy. Missing values can cause errors in models or lead to biased results.\n",
        "# Here, we employ common strategies to handle them:\n",
        "\n",
        "# 2.1 Drop rows where 'age' is missing.\n",
        "# Rationale: 'age' is a crucial demographic feature. If an age is missing, it's hard to impute accurately\n",
        "# without more complex methods. Dropping the row is a simple solution for a small dataset.\n",
        "df.dropna(subset=['age'], inplace=True)\n",
        "print(\"\\n--- After dropping rows with missing 'age' ---\")\n",
        "print(df.isnull().sum()) # Verify remaining missing values\n",
        "print(df.head()) # See updated DataFrame\n",
        "\n",
        "\n",
        "# 2.2 Fill missing 'annual_income' values with the MEAN of the 'annual_income' column.\n",
        "# Rationale: Annual income is numerical. Filling with the mean (average) is a simple imputation\n",
        "# strategy that preserves the overall distribution of the column, preventing data loss.\n",
        "mean_annual_income = df['annual_income'].mean()\n",
        "df['annual_income'] = df['annual_income'].fillna(mean_annual_income) # Assign back to avoid FutureWarning\n",
        "print(f\"\\n--- After filling missing 'annual_income' with mean ({mean_annual_income:.2f}) ---\")\n",
        "print(df.isnull().sum())\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# 2.3 Fill missing 'last_purchase_amount' values with 0.\n",
        "# Rationale: For purchase amounts, a missing value might imply no recent purchase,\n",
        "# or a zero-value purchase, so imputing with 0 is a reasonable business assumption here.\n",
        "df['last_purchase_amount'] = df['last_purchase_amount'].fillna(0) # Assign back to avoid FutureWarning\n",
        "print(\"\\n--- After filling missing 'last_purchase_amount' with 0 ---\")\n",
        "print(df.isnull().sum())\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n--- Final Cleaned DataFrame Head ---\")\n",
        "print(df.head())\n",
        "print(\"\\n--- Final Missing Values Count (Should all be 0) ---\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScvRvERrlPpH",
        "outputId": "0966a3fd-2fa5-4123-e7e0-eb4fcfcf491a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- After dropping rows with missing 'age' ---\n",
            "customer_id             0\n",
            "age                     0\n",
            "gender                  0\n",
            "annual_income           1\n",
            "has_loyalty_card        0\n",
            "last_purchase_amount    0\n",
            "dtype: int64\n",
            "   customer_id   age  gender  annual_income  has_loyalty_card  \\\n",
            "0          101  34.0  Female        55000.0              True   \n",
            "1          102  45.0    Male        70000.0             False   \n",
            "2          103  28.0  Female        48000.0              True   \n",
            "3          104  52.0    Male        85000.0              True   \n",
            "5          106  30.0    Male            NaN              True   \n",
            "\n",
            "   last_purchase_amount  \n",
            "0                120.50  \n",
            "1                 23.10  \n",
            "2                300.00  \n",
            "3                 75.25  \n",
            "5                 50.00  \n",
            "\n",
            "--- After filling missing 'annual_income' with mean (68333.33) ---\n",
            "customer_id             0\n",
            "age                     0\n",
            "gender                  0\n",
            "annual_income           0\n",
            "has_loyalty_card        0\n",
            "last_purchase_amount    0\n",
            "dtype: int64\n",
            "   customer_id   age  gender  annual_income  has_loyalty_card  \\\n",
            "0          101  34.0  Female   55000.000000              True   \n",
            "1          102  45.0    Male   70000.000000             False   \n",
            "2          103  28.0  Female   48000.000000              True   \n",
            "3          104  52.0    Male   85000.000000              True   \n",
            "5          106  30.0    Male   68333.333333              True   \n",
            "\n",
            "   last_purchase_amount  \n",
            "0                120.50  \n",
            "1                 23.10  \n",
            "2                300.00  \n",
            "3                 75.25  \n",
            "5                 50.00  \n",
            "\n",
            "--- After filling missing 'last_purchase_amount' with 0 ---\n",
            "customer_id             0\n",
            "age                     0\n",
            "gender                  0\n",
            "annual_income           0\n",
            "has_loyalty_card        0\n",
            "last_purchase_amount    0\n",
            "dtype: int64\n",
            "   customer_id   age  gender  annual_income  has_loyalty_card  \\\n",
            "0          101  34.0  Female   55000.000000              True   \n",
            "1          102  45.0    Male   70000.000000             False   \n",
            "2          103  28.0  Female   48000.000000              True   \n",
            "3          104  52.0    Male   85000.000000              True   \n",
            "5          106  30.0    Male   68333.333333              True   \n",
            "\n",
            "   last_purchase_amount  \n",
            "0                120.50  \n",
            "1                 23.10  \n",
            "2                300.00  \n",
            "3                 75.25  \n",
            "5                 50.00  \n",
            "\n",
            "--- Final Cleaned DataFrame Head ---\n",
            "   customer_id   age  gender  annual_income  has_loyalty_card  \\\n",
            "0          101  34.0  Female   55000.000000              True   \n",
            "1          102  45.0    Male   70000.000000             False   \n",
            "2          103  28.0  Female   48000.000000              True   \n",
            "3          104  52.0    Male   85000.000000              True   \n",
            "5          106  30.0    Male   68333.333333              True   \n",
            "\n",
            "   last_purchase_amount  \n",
            "0                120.50  \n",
            "1                 23.10  \n",
            "2                300.00  \n",
            "3                 75.25  \n",
            "5                 50.00  \n",
            "\n",
            "--- Final Missing Values Count (Should all be 0) ---\n",
            "customer_id             0\n",
            "age                     0\n",
            "gender                  0\n",
            "annual_income           0\n",
            "has_loyalty_card        0\n",
            "last_purchase_amount    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation for Machine Learning\n",
        "\n",
        "After cleaning, the data needs further preparation to be suitable for a machine learning model. This involves:\n",
        "\n",
        "Handling Categorical Data: Converting text-based categories (like 'gender') into numerical representations that models can understand.\n",
        "Adding Target Variable: Introducing the churn column, which is the variable our model will learn to predict.\n",
        "Defining Features (X) and Target (y): Separating the input variables from the output variable.\n",
        "Splitting Data: Dividing the dataset into training and testing sets to ensure robust model evaluation and prevent overfitting.\n",
        "Feature Scaling: Standardizing numerical features to ensure all features contribute equally to the model's learning process, especially for algorithms like Logistic Regression."
      ],
      "metadata": {
        "id": "3A0_urIJlTUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Data Preparation for Machine Learning ---\n",
        "\n",
        "# 3.1 Handle Categorical Data: Convert 'gender' to numerical (Label Encoding)\n",
        "# Rationale: ML models require numerical input. For binary categories, mapping 'Female' to 0 and 'Male' to 1 is a simple encoding.\n",
        "df['gender_encoded'] = df['gender'].map({'Female': 0, 'Male': 1})\n",
        "df.drop('gender', axis=1, inplace=True) # Drop the original 'gender' column after encoding\n",
        "print(\"\\n--- After Gender Encoding ---\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# 3.2 Add a dummy 'churn' column (0=No Churn, 1=Churn)\n",
        "# Rationale: This simulates the target variable we want to predict. In a real scenario, this column would be part of the raw data.\n",
        "# The number of values here MUST match the number of rows in your 'df' after cleaning!\n",
        "# (Original 8 rows - 1 dropped row = 7 rows)\n",
        "df['churn'] = [0, 1, 0, 0, 1, 0, 1]\n",
        "print(\"\\n--- DataFrame with Churn Column ---\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# 3.3 Define X (features) and y (target)\n",
        "# X contains the independent variables (features) used for prediction.\n",
        "# y contains the dependent variable (target) that the model predicts.\n",
        "X = df[['age', 'annual_income', 'last_purchase_amount', 'has_loyalty_card', 'gender_encoded']]\n",
        "y = df['churn']\n",
        "print(\"\\n--- Features (X) Head ---\")\n",
        "print(X.head())\n",
        "print(\"\\n--- Target (y) Head ---\")\n",
        "print(y.head())\n",
        "\n",
        "\n",
        "# 3.4 Split Data for Training and Testing\n",
        "# Rationale: This is critical for evaluating model performance on unseen data.\n",
        "# 80% of the data will be used for training, 20% for testing.\n",
        "# random_state ensures the split is reproducible.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "\n",
        "# 3.5 Scale the Features (X_train and X_test)\n",
        "# Rationale: Scaling ensures that features with larger numerical ranges (like annual_income)\n",
        "# don't disproportionately influence the model compared to features with smaller ranges (like age).\n",
        "# StandardScaler transforms data to have a mean of 0 and a standard deviation of 1.\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train) # Fit scaler on training data, then transform\n",
        "X_test_scaled = scaler.transform(X_test)     # Use the *same* fitted scaler to transform test data\n",
        "print(\"\\nFeatures scaled for training and testing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs01FovKle66",
        "outputId": "cd686019-818f-461a-aaed-58b0e0d3608b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- After Gender Encoding ---\n",
            "   customer_id   age  annual_income  has_loyalty_card  last_purchase_amount  \\\n",
            "0          101  34.0   55000.000000              True                120.50   \n",
            "1          102  45.0   70000.000000             False                 23.10   \n",
            "2          103  28.0   48000.000000              True                300.00   \n",
            "3          104  52.0   85000.000000              True                 75.25   \n",
            "5          106  30.0   68333.333333              True                 50.00   \n",
            "\n",
            "   gender_encoded  \n",
            "0               0  \n",
            "1               1  \n",
            "2               0  \n",
            "3               1  \n",
            "5               1  \n",
            "\n",
            "--- DataFrame with Churn Column ---\n",
            "   customer_id   age  annual_income  has_loyalty_card  last_purchase_amount  \\\n",
            "0          101  34.0   55000.000000              True                120.50   \n",
            "1          102  45.0   70000.000000             False                 23.10   \n",
            "2          103  28.0   48000.000000              True                300.00   \n",
            "3          104  52.0   85000.000000              True                 75.25   \n",
            "5          106  30.0   68333.333333              True                 50.00   \n",
            "\n",
            "   gender_encoded  churn  \n",
            "0               0      0  \n",
            "1               1      1  \n",
            "2               0      0  \n",
            "3               1      0  \n",
            "5               1      1  \n",
            "\n",
            "--- Features (X) Head ---\n",
            "    age  annual_income  last_purchase_amount  has_loyalty_card  gender_encoded\n",
            "0  34.0   55000.000000                120.50              True               0\n",
            "1  45.0   70000.000000                 23.10             False               1\n",
            "2  28.0   48000.000000                300.00              True               0\n",
            "3  52.0   85000.000000                 75.25              True               1\n",
            "5  30.0   68333.333333                 50.00              True               1\n",
            "\n",
            "--- Target (y) Head ---\n",
            "0    0\n",
            "1    1\n",
            "2    0\n",
            "3    0\n",
            "5    1\n",
            "Name: churn, dtype: int64\n",
            "\n",
            "Shape of X_train: (5, 5)\n",
            "Shape of X_test: (2, 5)\n",
            "Shape of y_train: (5,)\n",
            "Shape of y_test: (2,)\n",
            "\n",
            "Features scaled for training and testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building: Logistic Regression\n",
        "\n",
        "For this binary classification problem (predicting churn: Yes/No), we chose Logistic Regression.\n",
        "\n",
        "Logistic Regression is a statistical model that, despite its \"regression\" in the name, is primarily used for binary classification. It estimates the probability of an instance belonging to a particular class. It's a simple yet powerful and interpretable algorithm, making it a good starting point for many classification tasks.\n",
        "The model is initialized with random_state for reproducibility and max_iter increased to ensure the optimization algorithm converges properly, addressing common warnings."
      ],
      "metadata": {
        "id": "6y62dNhglpms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Build and Train Your Machine Learning Model ---\n",
        "\n",
        "print(\"\\n--- Building and Training the Model ---\")\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "# max_iter increased to help the solver converge and avoid warnings\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Train (fit) the model using your SCALED TRAINING data\n",
        "# The model learns patterns from X_train_scaled to predict y_train\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\"Model training complete!\")\n",
        "\n",
        "\n",
        "# Make a prediction for one customer from your X_test data\n",
        "# This demonstrates the model's ability to predict on unseen, scaled features.\n",
        "sample_customer_index = 0\n",
        "sample_customer_features_scaled = X_test_scaled[sample_customer_index].reshape(1, -1)\n",
        "\n",
        "# Get the actual churn value for this sample customer from y_test for comparison\n",
        "actual_churn_value = y_test.iloc[sample_customer_index]\n",
        "\n",
        "# Make the prediction for the single sample\n",
        "predicted_churn_sample = model.predict(sample_customer_features_scaled)\n",
        "\n",
        "print(f\"\\nFeatures of the sample test customer (scaled array):\\n{X_test_scaled[sample_customer_index]}\")\n",
        "print(f\"Original Features of the sample test customer:\\n{X_test.iloc[sample_customer_index]}\") # Show original for context\n",
        "print(f\"Actual Churn for this customer: {actual_churn_value}\")\n",
        "print(f\"Predicted Churn for this customer: {predicted_churn_sample[0]}\") # [0] to get the single value from the array\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hDqCfDjls9Y",
        "outputId": "d8993333-744b-4767-a528-42504112f780"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building and Training the Model ---\n",
            "Model training complete!\n",
            "\n",
            "Features of the sample test customer (scaled array):\n",
            "[-0.62740222 -1.0226094  -0.03760807  0.5        -1.22474487]\n",
            "Original Features of the sample test customer:\n",
            "age                        34.0\n",
            "annual_income           55000.0\n",
            "last_purchase_amount      120.5\n",
            "has_loyalty_card           True\n",
            "gender_encoded                0\n",
            "Name: 0, dtype: object\n",
            "Actual Churn for this customer: 0\n",
            "Predicted Churn for this customer: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results and Insights\n",
        "\n",
        "After training the Logistic Regression model, we evaluate its performance on the unseen test set.\n",
        "\n",
        "Sample Prediction Insight:\n",
        "The model predicted a churn status of {predicted_churn_sample[0]} for a customer with original features {X_test.iloc[sample_customer_index].to_dict()} whose actual churn status was {actual_churn_value}. This single prediction gives a snapshot of how the model performs on an individual case.\n",
        "\n",
        "Overall Model Performance:\n",
        "To assess the model's generalizability, we evaluate it on the entire test set (X_test).\n",
        "\n",
        "Accuracy: Measures the proportion of correctly predicted instances out of the total instances.\n",
        "Classification Report: Provides more detailed metrics for each class (0=No Churn, 1=Churn):\n",
        "Precision: Of all instances predicted as a certain class, how many were actually that class? (e.g., of all predicted churners, how many actually churned?)\n",
        "Recall: Of all instances that actually belong to a certain class, how many did the model correctly identify? (e.g., of all actual churners, how many did the model catch?)\n",
        "F1-Score: The harmonic mean of precision and recall, offering a balance between the two.\n",
        "Support: The number of actual occurrences of each class in the test set.\n",
        "(Note: Due to the very small size of this mock dataset, the accuracy and classification report may show extreme values or appear trivial. In real-world scenarios, these metrics are crucial for understanding a model's strengths and weaknesses.)"
      ],
      "metadata": {
        "id": "WlpU0UkelyLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Model Evaluation ---\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Test Set ---\")\n",
        "\n",
        "# Predict churn for the entire X_test_scaled set\n",
        "# This provides predictions for all customers in the test set, which we compare to y_test.\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and print overall accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on Test Set: {accuracy:.2f}\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "# This shows precision, recall, and f1-score for each class (0 and 1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n--- Project Complete! ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vZ-hYzWl7w5",
        "outputId": "2f5211ab-153e-4937-f370-23a548e953d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Evaluation on Test Set ---\n",
            "Model Accuracy on Test Set: 0.50\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "\n",
            "--- Project Complete! ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Future Work/Improvements\n",
        "\n",
        "This project provides a foundational understanding. For a more robust and production-ready solution, several improvements could be considered:\n",
        "\n",
        "More Data: Real-world datasets are much larger and more diverse.\n",
        "Feature Engineering: Creating new, more informative features from existing ones (e.g., days_since_last_purchase).\n",
        "Advanced Data Cleaning: Handling outliers, more sophisticated imputation methods for missing data.\n",
        "Other Models: Experimenting with different machine learning algorithms (e.g., RandomForestClassifier, GradientBoostingClassifier) which might perform better.\n",
        "Hyperparameter Tuning: Optimizing the settings of the chosen model for better performance.\n",
        "Cross-Validation: A more robust method for evaluating model performance on small datasets.\n",
        "Deployment: Turning the model into an API or integrating it into a business application.\n",
        "This project serves as an excellent starting point for further exploration and skill development in AI and machine learning."
      ],
      "metadata": {
        "id": "XDDql5Qkl-eG"
      }
    }
  ]
}